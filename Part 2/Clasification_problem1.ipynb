{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras --upgrade\n",
    "#!pip install tensorflow --upgrade\n",
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 21:04:20.208527: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, filters\n",
    "from skimage import feature\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from skimage import feature, draw\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import imblearn as imb\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2783, 2304)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('Xtrain1.npy')\n",
    "y_train = np.load('Ytrain1.npy')\n",
    "X_test = np.load('Xtest1.npy')\n",
    "X_train1_extra = np.load('Xtrain1_extra.npy')\n",
    "# Size of the training set\n",
    "\n",
    "print(X_train.shape) # 2700 images of size 48x48\n",
    "\n",
    "# Hot Encoding the labels\n",
    "train_labels = keras.utils.to_categorical(y_train,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = X_train.reshape(X_train.shape[0],48,48)    # Reshape the images to 48x48\n",
    "\n",
    "new = im.copy() # Copy the images to a new array\n",
    "\n",
    "threshold = 200\n",
    "for sample in range(im.shape[0]):\n",
    "\n",
    "  # Oustanding boundaries\n",
    "  for i in range(im.shape[1]):\n",
    "      for j in range(im.shape[2]):\n",
    "          if (im[sample][i][j] > threshold) | (im[sample][i][j] < 50):\n",
    "              new[sample][i][j] = 255\n",
    "          else:\n",
    "              new[sample][i][j] = 0\n",
    "\n",
    "  # Removing isolated pixels\n",
    "  for i in range(new.shape[1]):\n",
    "      for j in range(new.shape[2]):\n",
    "          if new[sample][i][j] == 255:\n",
    "              if (i>0) and (j>0) and (i<new.shape[1]-1) and (j<new.shape[2]-1):\n",
    "                  if ((new[sample][i-1][j]==0) and (new[sample][i+1][j]==0) and\n",
    "                      (new[sample][i][j-1]==0) and (new[sample][i][j+1]==0) and\n",
    "                      (new[sample][i-1][j-1]==0) and (new[sample][i-1][j+1]==0) and\n",
    "                      (new[sample][i+1][j-1]==0) and (new[sample][i+1][j+1]==0)):\n",
    "\n",
    "                        new[sample][i][j] = 0\n",
    "\n",
    "\n",
    "\n",
    "#m = im.imshow(im,cmap='gray')\n",
    "#im = im(as_grey=True)\n",
    "#new = filters.gaussian(new,sigma=0.5)  # Ajusta sigma para controlar el nivel de suavizado\n",
    "#new= filters.median(new)  # Ajusta sigma para controlar el nivel de suavizado\n",
    "#image_gaussian = feature.canny(im, sigma=3)  # Ajusta sigma según el nivel de detección de bordes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Flatten the images\n",
    "X_train_processed = new.reshape(new.shape[0],48*48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples with class 0 : 1006\n",
      "The number of training samples with class 1 : 1777\n",
      "The percentage of training samples with class 0 : 0.566122678671919\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of training samples with class 0 :\", np.sum(y_train==0))\n",
    "print(\"The number of training samples with class 1 :\", np.sum(y_train==1))\n",
    "print(\"The percentage of training samples with class 0 :\", np.sum(y_train==0)/np.sum(y_train==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove randomly the saples from class 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2782, 2304)\n"
     ]
    }
   ],
   "source": [
    "#Random undersampling\n",
    "rus = imb.under_sampling.RandomUnderSampler(sampling_strategy=np.sum(y_train==0)/np.sum(y_train==1))\n",
    "\n",
    "X_train_RUS, y_train_RUS = rus.fit_resample(X_train_processed, y_train)\n",
    "X_train_RUS, X_val_RUS, y_train_RUS, y_val_RUS = train_test_split(X_train_RUS,y_train_RUS, test_size=0.2)\n",
    "\n",
    "# One hot encoding\n",
    "train_labels_RUS = keras.utils.to_categorical(y_train_RUS,2)\n",
    "val_labels_RUS = keras.utils.to_categorical(y_val_RUS,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly replicate data from class 0 to have the same amount as class 1.\n",
    "\n",
    "\n",
    "IT CAN INCREASE OVERFITTING !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples with class 0 after ROS : 1777\n",
      "The number of training samples with class 1 after ROS : 1777\n"
     ]
    }
   ],
   "source": [
    "ros = imb.over_sampling.RandomOverSampler(random_state=None)\n",
    "\n",
    "X_train_ROS, y_train_ROS = ros.fit_resample(X_train_processed, y_train)\n",
    "X_train_ROS, X_val_ROS, y_train_ROS, y_val_ROS = train_test_split(X_train_ROS, y_train_ROS, test_size=0.2)\n",
    "\n",
    "# One hot encoding\n",
    "train_labels_ROS = keras.utils.to_categorical(y_train_ROS,2)\n",
    "val_labels_ROS = keras.utils.to_categorical(y_val_ROS,2)\n",
    "\n",
    "print(\"The number of training samples with class 0 after ROS :\", np.sum(y_train_ROS==0)+np.sum(y_val_ROS==0))\n",
    "print(\"The number of training samples with class 1 after ROS :\", np.sum(y_train_ROS==1)+np.sum(y_val_ROS==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly choose a subset of the minority class and we randomly create new samples. \n",
    "\n",
    "We use a modified version because SMOTE is not effective on high dimensional datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified SMOTE : MSMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "\n",
    "The size of input layer is : $48*48$ \n",
    "\n",
    "The number of hidden layers is between 2 and 5: giving the number of samples. \n",
    "2 if under 10 000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">631,362</span> (2.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m631,362\u001b[0m (2.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">631,362</span> (2.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m631,362\u001b[0m (2.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "\n",
    "#0.95 with  256 -> 128 -> 64 -> 2\n",
    "#0.88 with 128 -> 64 -> 32 -> 2\n",
    "#0.81 with 128 -> 64 -> 32 -> 16 -> 2\n",
    "#0.86 with 256 -> 128 -> 64 -> 32 -> 2\n",
    "\n",
    "\n",
    "# Input layer\n",
    "model.add(Dense(256, input_shape=(48*48,), activation='relu')) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense((64), activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "epochs=150\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.6141 - loss: 8.3978 - val_accuracy: 0.6984 - val_loss: 2.1835\n",
      "Epoch 2/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9221 - loss: 0.8363 - val_accuracy: 0.7307 - val_loss: 1.8069\n",
      "Epoch 3/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9714 - loss: 0.2814 - val_accuracy: 0.7469 - val_loss: 1.8934\n",
      "Epoch 4/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9955 - loss: 0.1125 - val_accuracy: 0.7720 - val_loss: 1.8781\n",
      "Epoch 5/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9942 - loss: 0.1371 - val_accuracy: 0.7594 - val_loss: 1.7567\n",
      "Epoch 6/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0356 - val_accuracy: 0.7487 - val_loss: 1.9132\n",
      "Epoch 7/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9846 - loss: 0.1606 - val_accuracy: 0.7415 - val_loss: 2.3080\n",
      "Epoch 8/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9913 - loss: 0.1270 - val_accuracy: 0.7594 - val_loss: 2.0781\n",
      "Epoch 9/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9978 - loss: 0.0568 - val_accuracy: 0.7343 - val_loss: 2.6909\n",
      "Epoch 10/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9958 - loss: 0.0698 - val_accuracy: 0.7558 - val_loss: 2.6863\n",
      "Epoch 11/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0535 - val_accuracy: 0.7522 - val_loss: 2.5214\n",
      "Epoch 12/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9991 - loss: 0.0354 - val_accuracy: 0.7469 - val_loss: 2.5047\n",
      "Epoch 13/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.7451 - val_loss: 2.6124\n",
      "Epoch 14/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.7504 - val_loss: 2.5985\n",
      "Epoch 15/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.7487 - val_loss: 2.5931\n",
      "Epoch 16/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.7504 - val_loss: 2.5920\n",
      "Epoch 17/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7487 - val_loss: 2.5939\n",
      "Epoch 18/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.7433 - val_loss: 2.5993\n",
      "Epoch 19/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7451 - val_loss: 2.6076\n",
      "Epoch 20/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7451 - val_loss: 2.6177\n",
      "Epoch 21/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.7469 - val_loss: 2.6278\n",
      "Epoch 22/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.7469 - val_loss: 2.6382\n",
      "Epoch 23/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7487 - val_loss: 2.6493\n",
      "Epoch 24/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7469 - val_loss: 2.6621\n",
      "Epoch 25/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7487 - val_loss: 2.6751\n",
      "Epoch 26/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7487 - val_loss: 2.6886\n",
      "Epoch 27/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7504 - val_loss: 2.7029\n",
      "Epoch 28/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7504 - val_loss: 2.7162\n",
      "Epoch 29/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7487 - val_loss: 2.7295\n",
      "Epoch 30/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7469 - val_loss: 2.7434\n",
      "Epoch 31/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7469 - val_loss: 2.7559\n",
      "Epoch 32/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.4232e-04 - val_accuracy: 0.7469 - val_loss: 2.7683\n",
      "Epoch 33/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.5074e-04 - val_accuracy: 0.7451 - val_loss: 2.7804\n",
      "Epoch 34/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 7.5262e-04 - val_accuracy: 0.7469 - val_loss: 2.7924\n",
      "Epoch 35/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 6.6241e-04 - val_accuracy: 0.7487 - val_loss: 2.8050\n",
      "Epoch 36/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.3944e-04 - val_accuracy: 0.7504 - val_loss: 2.8160\n",
      "Epoch 37/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.3960e-04 - val_accuracy: 0.7504 - val_loss: 2.8284\n",
      "Epoch 38/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 4.4732e-04 - val_accuracy: 0.7504 - val_loss: 2.8387\n",
      "Epoch 39/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.2917e-04 - val_accuracy: 0.7504 - val_loss: 2.8502\n",
      "Epoch 40/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.4480e-04 - val_accuracy: 0.7504 - val_loss: 2.8613\n",
      "Epoch 41/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 3.9953e-04 - val_accuracy: 0.7504 - val_loss: 2.8709\n",
      "Epoch 42/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.8072e-04 - val_accuracy: 0.7504 - val_loss: 2.8817\n",
      "Epoch 43/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 3.6985e-04 - val_accuracy: 0.7522 - val_loss: 2.8912\n",
      "Epoch 44/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.9570e-04 - val_accuracy: 0.7522 - val_loss: 2.9004\n",
      "Epoch 45/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.2015e-04 - val_accuracy: 0.7522 - val_loss: 2.9093\n",
      "Epoch 46/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.4042e-04 - val_accuracy: 0.7522 - val_loss: 2.9194\n",
      "Epoch 47/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.1416e-04 - val_accuracy: 0.7522 - val_loss: 2.9279\n",
      "Epoch 48/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 1.9431e-04 - val_accuracy: 0.7522 - val_loss: 2.9362\n",
      "Epoch 49/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.0637e-04 - val_accuracy: 0.7522 - val_loss: 2.9457\n",
      "Epoch 50/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.9395e-04 - val_accuracy: 0.7522 - val_loss: 2.9541\n",
      "Epoch 51/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.8523e-04 - val_accuracy: 0.7522 - val_loss: 2.9627\n",
      "Epoch 52/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 1.5705e-04 - val_accuracy: 0.7504 - val_loss: 2.9712\n",
      "Epoch 53/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.6934e-04 - val_accuracy: 0.7487 - val_loss: 2.9801\n",
      "Epoch 54/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.3542e-04 - val_accuracy: 0.7487 - val_loss: 2.9883\n",
      "Epoch 55/150\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 1.2374e-04 - val_accuracy: 0.7487 - val_loss: 2.9971\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.lines.Line2D at 0x7f94a2038b50>], None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate = lr)\n",
    "model.compile(optimizer = adam,\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Définir le callback EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',   # The quantity to be monitored\n",
    "    patience=50,           # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True,  # restore the best model\n",
    "    mode='min',           # consider the quantity to be monitored as minimum\n",
    "    verbose=1             # a message will be printed\n",
    ")\n",
    "\n",
    "#MLP with early stopping\n",
    "history = model.fit(x = X_train_RUS,\n",
    "                    y=train_labels_RUS,\n",
    "                    epochs = epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data = (X_val_RUS,val_labels_RUS),\n",
    "                    callbacks = [early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "\n",
    "####PLOT EVOLUTION\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(history.history['loss'], label='train'),\n",
    "plt.plot(history.history['val_loss'], label='validation'), plt.show()\n",
    "plt.plot(history.history['accuracy'], label='train'),\n",
    "plt.plot(history.history['val_accuracy'], label='validation'), plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - accuracy: 0.9415 - loss: 0.6230 - val_accuracy: 0.8453 - val_loss: 3.4743\n",
      "Epoch 2/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9299 - loss: 1.4484 - val_accuracy: 0.8636 - val_loss: 1.2952\n",
      "Epoch 3/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9589 - loss: 0.4629 - val_accuracy: 0.9128 - val_loss: 0.7285\n",
      "Epoch 4/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9704 - loss: 0.2224 - val_accuracy: 0.8931 - val_loss: 0.9415\n",
      "Epoch 5/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9874 - loss: 0.1182 - val_accuracy: 0.9086 - val_loss: 0.8486\n",
      "Epoch 6/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0156 - val_accuracy: 0.9030 - val_loss: 1.2564\n",
      "Epoch 7/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9870 - loss: 0.1676 - val_accuracy: 0.8186 - val_loss: 1.8331\n",
      "Epoch 8/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9809 - loss: 0.1884 - val_accuracy: 0.8636 - val_loss: 1.3869\n",
      "Epoch 9/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9824 - loss: 0.2106 - val_accuracy: 0.8861 - val_loss: 1.2587\n",
      "Epoch 10/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9824 - loss: 0.1000 - val_accuracy: 0.8664 - val_loss: 1.9804\n",
      "Epoch 11/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9883 - loss: 0.2047 - val_accuracy: 0.8861 - val_loss: 1.0913\n",
      "Epoch 12/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9975 - loss: 0.0090 - val_accuracy: 0.8819 - val_loss: 1.0545\n",
      "Epoch 13/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 5.5377e-04 - val_accuracy: 0.8833 - val_loss: 1.0368\n",
      "Epoch 14/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.3894e-04 - val_accuracy: 0.8833 - val_loss: 1.0391\n",
      "Epoch 15/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.9246e-04 - val_accuracy: 0.8833 - val_loss: 1.0402\n",
      "Epoch 16/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.4454e-04 - val_accuracy: 0.8833 - val_loss: 1.0416\n",
      "Epoch 17/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.0327e-04 - val_accuracy: 0.8819 - val_loss: 1.0431\n",
      "Epoch 18/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.5210e-04 - val_accuracy: 0.8805 - val_loss: 1.0441\n",
      "Epoch 19/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.0097e-04 - val_accuracy: 0.8805 - val_loss: 1.0453\n",
      "Epoch 20/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.8617e-04 - val_accuracy: 0.8805 - val_loss: 1.0463\n",
      "Epoch 21/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.8283e-04 - val_accuracy: 0.8805 - val_loss: 1.0473\n",
      "Epoch 22/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.2813e-04 - val_accuracy: 0.8805 - val_loss: 1.0483\n",
      "Epoch 23/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.4570e-04 - val_accuracy: 0.8805 - val_loss: 1.0494\n",
      "Epoch 24/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.3032e-04 - val_accuracy: 0.8805 - val_loss: 1.0501\n",
      "Epoch 25/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.0226e-04 - val_accuracy: 0.8805 - val_loss: 1.0510\n",
      "Epoch 26/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 8.4155e-05 - val_accuracy: 0.8805 - val_loss: 1.0520\n",
      "Epoch 27/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 9.7711e-05 - val_accuracy: 0.8805 - val_loss: 1.0530\n",
      "Epoch 28/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 8.0172e-05 - val_accuracy: 0.8819 - val_loss: 1.0538\n",
      "Epoch 29/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 7.3030e-05 - val_accuracy: 0.8819 - val_loss: 1.0549\n",
      "Epoch 30/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 6.1423e-05 - val_accuracy: 0.8819 - val_loss: 1.0558\n",
      "Epoch 31/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 5.3211e-05 - val_accuracy: 0.8819 - val_loss: 1.0565\n",
      "Epoch 32/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 5.6565e-05 - val_accuracy: 0.8819 - val_loss: 1.0574\n",
      "Epoch 33/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 5.2845e-05 - val_accuracy: 0.8819 - val_loss: 1.0580\n",
      "Epoch 34/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.8391e-05 - val_accuracy: 0.8819 - val_loss: 1.0587\n",
      "Epoch 35/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 5.1383e-05 - val_accuracy: 0.8819 - val_loss: 1.0594\n",
      "Epoch 36/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.9469e-05 - val_accuracy: 0.8819 - val_loss: 1.0603\n",
      "Epoch 37/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.0678e-05 - val_accuracy: 0.8819 - val_loss: 1.0610\n",
      "Epoch 38/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.5656e-05 - val_accuracy: 0.8819 - val_loss: 1.0618\n",
      "Epoch 39/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 3.1716e-05 - val_accuracy: 0.8805 - val_loss: 1.0624\n",
      "Epoch 40/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 3.6108e-05 - val_accuracy: 0.8805 - val_loss: 1.0630\n",
      "Epoch 41/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 3.1325e-05 - val_accuracy: 0.8805 - val_loss: 1.0636\n",
      "Epoch 42/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.9894e-05 - val_accuracy: 0.8805 - val_loss: 1.0642\n",
      "Epoch 43/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.5629e-05 - val_accuracy: 0.8790 - val_loss: 1.0650\n",
      "Epoch 44/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.5720e-05 - val_accuracy: 0.8776 - val_loss: 1.0662\n",
      "Epoch 45/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 2.2338e-05 - val_accuracy: 0.8776 - val_loss: 1.0670\n",
      "Epoch 46/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.1838e-05 - val_accuracy: 0.8776 - val_loss: 1.0678\n",
      "Epoch 47/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.3507e-05 - val_accuracy: 0.8776 - val_loss: 1.0687\n",
      "Epoch 48/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.0297e-05 - val_accuracy: 0.8776 - val_loss: 1.0694\n",
      "Epoch 49/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.9965e-05 - val_accuracy: 0.8776 - val_loss: 1.0704\n",
      "Epoch 50/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.9043e-05 - val_accuracy: 0.8776 - val_loss: 1.0714\n",
      "Epoch 51/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 1.5258e-05 - val_accuracy: 0.8776 - val_loss: 1.0721\n",
      "Epoch 52/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.6138e-05 - val_accuracy: 0.8776 - val_loss: 1.0729\n",
      "Epoch 53/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4131e-05 - val_accuracy: 0.8776 - val_loss: 1.0736\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.lines.Line2D at 0x7f94a313cd30>], None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "adam = keras.optimizers.Adam(learning_rate = lr)\n",
    "model.compile(optimizer = adam,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#MLP with early stopping\n",
    "history = model.fit(x = X_train_ROS,\n",
    "                    y=train_labels_ROS,\n",
    "                    epochs = epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data = (X_val_ROS,val_labels_ROS),\n",
    "                    callbacks = [early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "\n",
    "####PLOT EVOLUTION\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(history.history['loss'], label='train'),\n",
    "plt.plot(history.history['val_loss'], label='train'), plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using X_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use X_extra and do prediction on it and then combine X_train and X_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = X_train1_extra.reshape(X_train1_extra.shape[0],48,48)    # Reshape the images to 48x48\n",
    "\n",
    "new = im.copy() # Copy the images to a new array\n",
    "\n",
    "threshold = 200\n",
    "for sample in range(im.shape[0]):\n",
    "\n",
    "  # Oustanding boundaries\n",
    "  for i in range(im.shape[1]):\n",
    "      for j in range(im.shape[2]):\n",
    "          if (im[sample][i][j] > threshold) | (im[sample][i][j] < 50):\n",
    "              new[sample][i][j] = 255\n",
    "          else:\n",
    "              new[sample][i][j] = 0\n",
    "\n",
    "  # Removing isolated pixels\n",
    "  for i in range(new.shape[1]):\n",
    "      for j in range(new.shape[2]):\n",
    "          if new[sample][i][j] == 255:\n",
    "              if (i>0) and (j>0) and (i<new.shape[1]-1) and (j<new.shape[2]-1):\n",
    "                  if ((new[sample][i-1][j]==0) and (new[sample][i+1][j]==0) and\n",
    "                      (new[sample][i][j-1]==0) and (new[sample][i][j+1]==0) and\n",
    "                      (new[sample][i-1][j-1]==0) and (new[sample][i-1][j+1]==0) and\n",
    "                      (new[sample][i+1][j-1]==0) and (new[sample][i+1][j+1]==0)):\n",
    "\n",
    "                        new[sample][i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(904, 2304)\n"
     ]
    }
   ],
   "source": [
    "X_train_extra_processed = new.reshape(new.shape[0],48*48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "The number of extra samples with class 0 : 452\n",
      "The number of extra samples with class 1 : 452\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_train_extra_processed)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(\"The number of extra samples with class 0 :\", np.sum(y_pred==0))\n",
    "print(\"The number of extra samples with class 1 :\", np.sum(y_pred==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples with class 0 after adding extra samples : 1458\n",
      "The number of training samples with class 1 after adding extra samples : 1777\n"
     ]
    }
   ],
   "source": [
    "# Adding the extra samples to the training set for class 0\n",
    "X_train_combined = np.concatenate((X_train_processed,X_train_extra_processed[y_pred==0]),axis=0)\n",
    "y_train_combined = np.concatenate((y_train,y_pred[y_pred==0]),axis=0)\n",
    "train_labels_ROS_combined = keras.utils.to_categorical(y_train_combined,2)\n",
    "print(\"The number of training samples with class 0 after adding extra samples :\", np.sum(y_train_combined==0))\n",
    "print(\"The number of training samples with class 1 after adding extra samples :\", np.sum(y_train_combined==1))\n",
    "\n",
    "# ROS\n",
    "ros = imb.over_sampling.RandomOverSampler(random_state=None)\n",
    "X_train_ROS_combined, y_train_ROS_combined = ros.fit_resample(X_train_combined, y_train_combined)\n",
    "X_train_ROS_combined, X_val_ROS_combined, y_train_ROS_combined, y_val_ROS_combined = train_test_split(X_train_ROS_combined, y_train_ROS_combined, test_size=0.2)\n",
    "train_labels_ROS_combined = keras.utils.to_categorical(y_train_ROS_combined,2)\n",
    "val_labels_ROS_combined = keras.utils.to_categorical(y_val_ROS_combined,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - accuracy: 0.9735 - loss: 0.5485 - val_accuracy: 0.9592 - val_loss: 0.5716\n",
      "Epoch 2/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9943 - loss: 0.0220 - val_accuracy: 0.9662 - val_loss: 0.4990\n",
      "Epoch 3/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9958 - loss: 0.0932 - val_accuracy: 0.9662 - val_loss: 0.8537\n",
      "Epoch 4/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9928 - loss: 0.0897 - val_accuracy: 0.9733 - val_loss: 0.6261\n",
      "Epoch 5/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9954 - loss: 0.3742 - val_accuracy: 0.9620 - val_loss: 0.6117\n",
      "Epoch 6/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9946 - loss: 0.2725 - val_accuracy: 0.9606 - val_loss: 0.6629\n",
      "Epoch 7/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9979 - loss: 0.0100 - val_accuracy: 0.9578 - val_loss: 0.8260\n",
      "Epoch 8/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.5025e-05 - val_accuracy: 0.9677 - val_loss: 0.7531\n",
      "Epoch 9/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9999 - loss: 4.1919e-04 - val_accuracy: 0.9662 - val_loss: 0.7746\n",
      "Epoch 10/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0018 - val_accuracy: 0.9648 - val_loss: 0.8087\n",
      "Epoch 11/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.3170e-07 - val_accuracy: 0.9648 - val_loss: 0.8055\n",
      "Epoch 12/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1800e-07 - val_accuracy: 0.9648 - val_loss: 0.8052\n",
      "Epoch 13/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.4979e-07 - val_accuracy: 0.9648 - val_loss: 0.8048\n",
      "Epoch 14/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.8665e-07 - val_accuracy: 0.9648 - val_loss: 0.8045\n",
      "Epoch 15/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 8.2392e-08 - val_accuracy: 0.9648 - val_loss: 0.8043\n",
      "Epoch 16/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6704e-07 - val_accuracy: 0.9648 - val_loss: 0.8041\n",
      "Epoch 17/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.4832e-08 - val_accuracy: 0.9648 - val_loss: 0.8039\n",
      "Epoch 18/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.4268e-07 - val_accuracy: 0.9648 - val_loss: 0.8038\n",
      "Epoch 19/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.0369e-08 - val_accuracy: 0.9648 - val_loss: 0.8036\n",
      "Epoch 20/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0680e-07 - val_accuracy: 0.9648 - val_loss: 0.8035\n",
      "Epoch 21/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 8.1443e-08 - val_accuracy: 0.9648 - val_loss: 0.8034\n",
      "Epoch 22/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.6660e-08 - val_accuracy: 0.9648 - val_loss: 0.8034\n",
      "Epoch 23/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2451e-07 - val_accuracy: 0.9648 - val_loss: 0.8034\n",
      "Epoch 24/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.0060e-08 - val_accuracy: 0.9648 - val_loss: 0.8027\n",
      "Epoch 25/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.5037e-08 - val_accuracy: 0.9648 - val_loss: 0.8026\n",
      "Epoch 26/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.7136e-08 - val_accuracy: 0.9648 - val_loss: 0.8025\n",
      "Epoch 27/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.8866e-08 - val_accuracy: 0.9648 - val_loss: 0.8024\n",
      "Epoch 28/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.6011e-08 - val_accuracy: 0.9648 - val_loss: 0.8023\n",
      "Epoch 29/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.1311e-08 - val_accuracy: 0.9648 - val_loss: 0.8022\n",
      "Epoch 30/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.5554e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 31/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.2867e-08 - val_accuracy: 0.9648 - val_loss: 0.8020\n",
      "Epoch 32/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.9027e-08 - val_accuracy: 0.9648 - val_loss: 0.8020\n",
      "Epoch 33/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 2.8528e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 34/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.4570e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 35/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.5610e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 36/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.5974e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 37/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.1182e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 38/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.2923e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 39/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.6222e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 40/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.9366e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 41/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.8514e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 42/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.0477e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 43/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.4488e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 44/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.5816e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 45/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.5183e-08 - val_accuracy: 0.9648 - val_loss: 0.8021\n",
      "Epoch 46/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.3110e-08 - val_accuracy: 0.9648 - val_loss: 0.8020\n",
      "Epoch 47/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.2580e-08 - val_accuracy: 0.9648 - val_loss: 0.8020\n",
      "Epoch 48/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.7663e-08 - val_accuracy: 0.9648 - val_loss: 0.8019\n",
      "Epoch 49/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.9021e-08 - val_accuracy: 0.9648 - val_loss: 0.8019\n",
      "Epoch 50/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.6700e-08 - val_accuracy: 0.9648 - val_loss: 0.8019\n",
      "Epoch 51/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.2289e-08 - val_accuracy: 0.9648 - val_loss: 0.8019\n",
      "Epoch 52/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.6314e-08 - val_accuracy: 0.9648 - val_loss: 0.8018\n",
      "Epoch 53/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1565e-08 - val_accuracy: 0.9648 - val_loss: 0.8018\n",
      "Epoch 54/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.5772e-08 - val_accuracy: 0.9648 - val_loss: 0.8017\n",
      "Epoch 55/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.3092e-08 - val_accuracy: 0.9648 - val_loss: 0.8017\n",
      "Epoch 56/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.3244e-08 - val_accuracy: 0.9648 - val_loss: 0.8016\n",
      "Epoch 57/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.9552e-08 - val_accuracy: 0.9648 - val_loss: 0.8015\n",
      "Epoch 58/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.9046e-08 - val_accuracy: 0.9648 - val_loss: 0.8014\n",
      "Epoch 59/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2114e-08 - val_accuracy: 0.9648 - val_loss: 0.8014\n",
      "Epoch 60/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.0509e-08 - val_accuracy: 0.9648 - val_loss: 0.8013\n",
      "Epoch 61/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.4584e-08 - val_accuracy: 0.9648 - val_loss: 0.8013\n",
      "Epoch 62/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.5789e-08 - val_accuracy: 0.9648 - val_loss: 0.8012\n",
      "Epoch 63/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.1534e-08 - val_accuracy: 0.9648 - val_loss: 0.8011\n",
      "Epoch 64/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8908e-08 - val_accuracy: 0.9648 - val_loss: 0.8010\n",
      "Epoch 65/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.9150e-08 - val_accuracy: 0.9648 - val_loss: 0.8009\n",
      "Epoch 66/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.0969e-08 - val_accuracy: 0.9648 - val_loss: 0.8009\n",
      "Epoch 67/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.4763e-08 - val_accuracy: 0.9648 - val_loss: 0.8008\n",
      "Epoch 68/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7163e-08 - val_accuracy: 0.9648 - val_loss: 0.8008\n",
      "Epoch 69/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0279e-08 - val_accuracy: 0.9648 - val_loss: 0.8007\n",
      "Epoch 70/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0980e-08 - val_accuracy: 0.9648 - val_loss: 0.8007\n",
      "Epoch 71/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.2733e-08 - val_accuracy: 0.9648 - val_loss: 0.8007\n",
      "Epoch 72/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.7994e-09 - val_accuracy: 0.9648 - val_loss: 0.8006\n",
      "Epoch 73/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.9538e-09 - val_accuracy: 0.9648 - val_loss: 0.8006\n",
      "Epoch 74/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.0331e-08 - val_accuracy: 0.9648 - val_loss: 0.8005\n",
      "Epoch 75/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.6690e-08 - val_accuracy: 0.9648 - val_loss: 0.8005\n",
      "Epoch 76/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.9181e-08 - val_accuracy: 0.9648 - val_loss: 0.8004\n",
      "Epoch 77/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.5644e-09 - val_accuracy: 0.9648 - val_loss: 0.8004\n",
      "Epoch 78/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.4477e-09 - val_accuracy: 0.9648 - val_loss: 0.8003\n",
      "Epoch 79/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.7722e-08 - val_accuracy: 0.9648 - val_loss: 0.8003\n",
      "Epoch 80/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 9.9702e-09 - val_accuracy: 0.9648 - val_loss: 0.8002\n",
      "Epoch 81/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.1585e-08 - val_accuracy: 0.9648 - val_loss: 0.8002\n",
      "Epoch 82/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.7898e-09 - val_accuracy: 0.9648 - val_loss: 0.8001\n",
      "Epoch 83/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.7496e-09 - val_accuracy: 0.9648 - val_loss: 0.8000\n",
      "Epoch 84/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.5734e-08 - val_accuracy: 0.9648 - val_loss: 0.8000\n",
      "Epoch 85/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.5093e-09 - val_accuracy: 0.9648 - val_loss: 0.7999\n",
      "Epoch 86/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.5949e-09 - val_accuracy: 0.9648 - val_loss: 0.7999\n",
      "Epoch 87/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.6216e-09 - val_accuracy: 0.9648 - val_loss: 0.7998\n",
      "Epoch 88/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.3903e-09 - val_accuracy: 0.9648 - val_loss: 0.7998\n",
      "Epoch 89/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0255e-08 - val_accuracy: 0.9648 - val_loss: 0.7997\n",
      "Epoch 90/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4935e-08 - val_accuracy: 0.9648 - val_loss: 0.7997\n",
      "Epoch 91/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.1257e-08 - val_accuracy: 0.9648 - val_loss: 0.7996\n",
      "Epoch 92/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.7885e-09 - val_accuracy: 0.9648 - val_loss: 0.7996\n",
      "Epoch 93/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.8879e-09 - val_accuracy: 0.9648 - val_loss: 0.7995\n",
      "Epoch 94/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 7.4414e-09 - val_accuracy: 0.9648 - val_loss: 0.7994\n",
      "Epoch 95/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.2260e-09 - val_accuracy: 0.9648 - val_loss: 0.7994\n",
      "Epoch 96/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 9.8867e-09 - val_accuracy: 0.9648 - val_loss: 0.7993\n",
      "Epoch 97/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.6916e-09 - val_accuracy: 0.9648 - val_loss: 0.7993\n",
      "Epoch 98/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.4344e-09 - val_accuracy: 0.9648 - val_loss: 0.7993\n",
      "Epoch 99/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.6215e-09 - val_accuracy: 0.9648 - val_loss: 0.7992\n",
      "Epoch 100/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.5372e-09 - val_accuracy: 0.9648 - val_loss: 0.7992\n",
      "Epoch 101/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.5216e-09 - val_accuracy: 0.9648 - val_loss: 0.7991\n",
      "Epoch 102/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.0758e-09 - val_accuracy: 0.9648 - val_loss: 0.7991\n",
      "Epoch 103/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 6.6108e-09 - val_accuracy: 0.9648 - val_loss: 0.7990\n",
      "Epoch 104/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.2004e-08 - val_accuracy: 0.9648 - val_loss: 0.7990\n",
      "Epoch 105/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.5946e-09 - val_accuracy: 0.9648 - val_loss: 0.7989\n",
      "Epoch 106/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.0232e-09 - val_accuracy: 0.9648 - val_loss: 0.7989\n",
      "Epoch 107/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 5.6615e-09 - val_accuracy: 0.9648 - val_loss: 0.7988\n",
      "Epoch 108/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.0840e-09 - val_accuracy: 0.9648 - val_loss: 0.7988\n",
      "Epoch 109/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.5117e-09 - val_accuracy: 0.9648 - val_loss: 0.7988\n",
      "Epoch 110/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 6.9991e-09 - val_accuracy: 0.9648 - val_loss: 0.7987\n",
      "Epoch 111/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.8062e-09 - val_accuracy: 0.9648 - val_loss: 0.7987\n",
      "Epoch 112/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 3.0542e-09 - val_accuracy: 0.9648 - val_loss: 0.7986\n",
      "Epoch 113/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.3469e-09 - val_accuracy: 0.9648 - val_loss: 0.7986\n",
      "Epoch 114/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.0674e-08 - val_accuracy: 0.9648 - val_loss: 0.7985\n",
      "Epoch 115/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 6.5743e-09 - val_accuracy: 0.9648 - val_loss: 0.7984\n",
      "Epoch 116/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 5.6308e-09 - val_accuracy: 0.9648 - val_loss: 0.7984\n",
      "Epoch 117/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.9944e-09 - val_accuracy: 0.9648 - val_loss: 0.7984\n",
      "Epoch 118/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.1364e-09 - val_accuracy: 0.9648 - val_loss: 0.7983\n",
      "Epoch 119/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 5.0885e-09 - val_accuracy: 0.9648 - val_loss: 0.7983\n",
      "Epoch 120/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.1626e-09 - val_accuracy: 0.9648 - val_loss: 0.7983\n",
      "Epoch 121/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.4696e-09 - val_accuracy: 0.9648 - val_loss: 0.7982\n",
      "Epoch 122/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.4003e-09 - val_accuracy: 0.9648 - val_loss: 0.7982\n",
      "Epoch 123/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 2.4902e-09 - val_accuracy: 0.9648 - val_loss: 0.7981\n",
      "Epoch 124/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.6439e-09 - val_accuracy: 0.9648 - val_loss: 0.7981\n",
      "Epoch 125/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 4.7627e-09 - val_accuracy: 0.9648 - val_loss: 0.7980\n",
      "Epoch 126/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.5149e-09 - val_accuracy: 0.9648 - val_loss: 0.7980\n",
      "Epoch 127/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 6.1082e-09 - val_accuracy: 0.9648 - val_loss: 0.7980\n",
      "Epoch 128/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 4.3519e-09 - val_accuracy: 0.9648 - val_loss: 0.7979\n",
      "Epoch 129/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.1428e-09 - val_accuracy: 0.9648 - val_loss: 0.7979\n",
      "Epoch 130/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.2915e-09 - val_accuracy: 0.9648 - val_loss: 0.7979\n",
      "Epoch 131/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.3833e-09 - val_accuracy: 0.9648 - val_loss: 0.7978\n",
      "Epoch 132/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.5270e-09 - val_accuracy: 0.9648 - val_loss: 0.7978\n",
      "Epoch 133/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.3823e-09 - val_accuracy: 0.9648 - val_loss: 0.7978\n",
      "Epoch 134/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.9281e-09 - val_accuracy: 0.9648 - val_loss: 0.7977\n",
      "Epoch 135/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.2049e-09 - val_accuracy: 0.9648 - val_loss: 0.7977\n",
      "Epoch 136/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.6709e-09 - val_accuracy: 0.9648 - val_loss: 0.7976\n",
      "Epoch 137/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.5657e-09 - val_accuracy: 0.9648 - val_loss: 0.7976\n",
      "Epoch 138/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.1394e-09 - val_accuracy: 0.9648 - val_loss: 0.7976\n",
      "Epoch 139/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.3132e-09 - val_accuracy: 0.9648 - val_loss: 0.7975\n",
      "Epoch 140/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 2.0893e-09 - val_accuracy: 0.9648 - val_loss: 0.7975\n",
      "Epoch 141/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 8.7536e-10 - val_accuracy: 0.9648 - val_loss: 0.7974\n",
      "Epoch 142/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8787e-09 - val_accuracy: 0.9648 - val_loss: 0.7974\n",
      "Epoch 143/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.1257e-09 - val_accuracy: 0.9648 - val_loss: 0.7974\n",
      "Epoch 144/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.2395e-09 - val_accuracy: 0.9648 - val_loss: 0.7974\n",
      "Epoch 145/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 4.1298e-09 - val_accuracy: 0.9648 - val_loss: 0.7973\n",
      "Epoch 146/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.6915e-09 - val_accuracy: 0.9648 - val_loss: 0.7973\n",
      "Epoch 147/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 3.5825e-09 - val_accuracy: 0.9648 - val_loss: 0.7973\n",
      "Epoch 148/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 1.6872e-09 - val_accuracy: 0.9648 - val_loss: 0.7972\n",
      "Epoch 149/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6301e-09 - val_accuracy: 0.9648 - val_loss: 0.7972\n",
      "Epoch 150/150\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 2.3047e-09 - val_accuracy: 0.9648 - val_loss: 0.7972\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.legend.Legend at 0x7f94923118b0>, None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "adam = keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "\n",
    "model.compile(optimizer = adam,\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "#MLP without early stopping\n",
    "history = model.fit(x = X_train_ROS_combined,\n",
    "                    y=train_labels_ROS_combined,\n",
    "                    epochs = epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data = (X_val_ROS_combined,val_labels_ROS_combined),\n",
    "                    callbacks = [early_stopping],\n",
    "                    verbose = 1)\n",
    "\n",
    "####PLOT EVOLUTION\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.plot(history.history['loss'], label='train'),\n",
    "plt.plot(history.history['val_loss'], label='val'), \n",
    "plt.legend(),plt.show()\n",
    "plt.plot(history.history['accuracy'], label='train'),\n",
    "plt.plot(history.history['val_accuracy'], label='val'),\n",
    "plt.legend(),plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2843, 2304)\n",
      "(2843,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.6140 - loss: 5.5886 - val_accuracy: 0.6982 - val_loss: 2.5865\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9310 - loss: 0.5985 - val_accuracy: 0.7544 - val_loss: 2.8177\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9798 - loss: 0.2378 - val_accuracy: 0.7228 - val_loss: 2.6842\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9874 - loss: 0.2240 - val_accuracy: 0.7404 - val_loss: 2.9607\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9905 - loss: 0.1059 - val_accuracy: 0.7263 - val_loss: 2.9542\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9964 - loss: 0.0752 - val_accuracy: 0.7509 - val_loss: 3.3319\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9947 - loss: 0.2183 - val_accuracy: 0.7439 - val_loss: 2.7355\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9868 - loss: 0.1497 - val_accuracy: 0.7298 - val_loss: 3.1754\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9729 - loss: 0.2578 - val_accuracy: 0.7439 - val_loss: 2.8764\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9629 - loss: 0.4231 - val_accuracy: 0.7509 - val_loss: 3.3715\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9765 - loss: 0.2643 - val_accuracy: 0.7333 - val_loss: 2.7569\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9924 - loss: 0.0817 - val_accuracy: 0.7684 - val_loss: 2.8907\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9986 - loss: 0.0181 - val_accuracy: 0.7614 - val_loss: 3.3683\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9987 - loss: 0.0169 - val_accuracy: 0.7509 - val_loss: 2.7498\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9995 - loss: 0.0141 - val_accuracy: 0.7614 - val_loss: 2.6930\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9960 - loss: 0.0253 - val_accuracy: 0.7684 - val_loss: 3.1133\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9995 - loss: 0.0055 - val_accuracy: 0.7474 - val_loss: 3.4244\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7579 - val_loss: 3.3544\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7579 - val_loss: 3.3628\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7544 - val_loss: 3.3698\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7544 - val_loss: 3.3774\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7579 - val_loss: 3.3857\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.6632e-04 - val_accuracy: 0.7579 - val_loss: 3.3928\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 6.5943e-04 - val_accuracy: 0.7579 - val_loss: 3.3998\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 6.0233e-04 - val_accuracy: 0.7579 - val_loss: 3.4067\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.7339e-04 - val_accuracy: 0.7579 - val_loss: 3.4138\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.2459e-04 - val_accuracy: 0.7579 - val_loss: 3.4213\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.2131e-04 - val_accuracy: 0.7579 - val_loss: 3.4280\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.8512e-04 - val_accuracy: 0.7544 - val_loss: 3.4354\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 3.5329e-04 - val_accuracy: 0.7579 - val_loss: 3.4426\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 3.0670e-04 - val_accuracy: 0.7579 - val_loss: 3.4507\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.9046e-04 - val_accuracy: 0.7579 - val_loss: 3.4571\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.7861e-04 - val_accuracy: 0.7614 - val_loss: 3.4635\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 2.4069e-04 - val_accuracy: 0.7614 - val_loss: 3.4691\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.0607e-04 - val_accuracy: 0.7614 - val_loss: 3.4742\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.8881e-04 - val_accuracy: 0.7614 - val_loss: 3.4791\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6761e-04 - val_accuracy: 0.7614 - val_loss: 3.4844\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.6381e-04 - val_accuracy: 0.7614 - val_loss: 3.4895\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 1.4953e-04 - val_accuracy: 0.7614 - val_loss: 3.4943\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 1.3900e-04 - val_accuracy: 0.7614 - val_loss: 3.4991\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.2891e-04 - val_accuracy: 0.7614 - val_loss: 3.5036\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 1.2999e-04 - val_accuracy: 0.7614 - val_loss: 3.5089\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.1224e-04 - val_accuracy: 0.7614 - val_loss: 3.5131\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.0514e-04 - val_accuracy: 0.7614 - val_loss: 3.5181\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 9.9404e-05 - val_accuracy: 0.7614 - val_loss: 3.5229\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.1895e-05 - val_accuracy: 0.7614 - val_loss: 3.5275\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.7691e-05 - val_accuracy: 0.7614 - val_loss: 3.5323\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 7.0552e-05 - val_accuracy: 0.7614 - val_loss: 3.5369\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 7.2782e-05 - val_accuracy: 0.7614 - val_loss: 3.5419\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.3026e-05 - val_accuracy: 0.7614 - val_loss: 3.5466\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 1: loss of 2.5865139961242676; compile_metrics of 69.82455849647522%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.6134 - loss: 5.2507 - val_accuracy: 0.7263 - val_loss: 2.1481\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9144 - loss: 0.6497 - val_accuracy: 0.7754 - val_loss: 1.5568\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9913 - loss: 0.1282 - val_accuracy: 0.7684 - val_loss: 1.7550\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9906 - loss: 0.1597 - val_accuracy: 0.7649 - val_loss: 1.9351\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9936 - loss: 0.0697 - val_accuracy: 0.7965 - val_loss: 1.7177\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9970 - loss: 0.0480 - val_accuracy: 0.7895 - val_loss: 1.6191\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9967 - loss: 0.0650 - val_accuracy: 0.7754 - val_loss: 1.6969\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.9967 - loss: 0.0528 - val_accuracy: 0.7825 - val_loss: 1.6943\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9945 - loss: 0.1237 - val_accuracy: 0.7860 - val_loss: 1.8774\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9965 - loss: 0.0812 - val_accuracy: 0.8140 - val_loss: 1.8500\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9975 - loss: 0.0522 - val_accuracy: 0.8140 - val_loss: 1.8979\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9870 - loss: 0.1166 - val_accuracy: 0.7965 - val_loss: 2.5311\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9652 - loss: 0.3792 - val_accuracy: 0.7298 - val_loss: 2.9371\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9709 - loss: 0.2164 - val_accuracy: 0.7754 - val_loss: 2.4595\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9905 - loss: 0.0756 - val_accuracy: 0.7789 - val_loss: 1.9805\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9769 - loss: 0.2347 - val_accuracy: 0.7684 - val_loss: 2.3646\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9884 - loss: 0.1178 - val_accuracy: 0.7719 - val_loss: 2.6474\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9914 - loss: 0.1058 - val_accuracy: 0.7614 - val_loss: 1.8815\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9943 - loss: 0.0349 - val_accuracy: 0.8140 - val_loss: 1.7338\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0081 - val_accuracy: 0.8000 - val_loss: 2.7102\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0127 - val_accuracy: 0.8000 - val_loss: 2.5078\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9997 - loss: 0.0025 - val_accuracy: 0.8140 - val_loss: 2.6815\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8105 - val_loss: 2.5381\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.4241e-04 - val_accuracy: 0.8070 - val_loss: 2.5162\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.6422e-04 - val_accuracy: 0.8105 - val_loss: 2.5279\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.1807e-04 - val_accuracy: 0.8140 - val_loss: 2.5381\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.4181e-04 - val_accuracy: 0.8140 - val_loss: 2.5476\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.4357e-04 - val_accuracy: 0.8140 - val_loss: 2.5555\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.5852e-04 - val_accuracy: 0.8140 - val_loss: 2.5639\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.8847e-04 - val_accuracy: 0.8140 - val_loss: 2.5712\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.5307e-04 - val_accuracy: 0.8140 - val_loss: 2.5786\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.3675e-04 - val_accuracy: 0.8175 - val_loss: 2.5864\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 3.1503e-04 - val_accuracy: 0.8175 - val_loss: 2.5936\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.4948e-04 - val_accuracy: 0.8175 - val_loss: 2.6006\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.7289e-04 - val_accuracy: 0.8175 - val_loss: 2.6074\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.3122e-04 - val_accuracy: 0.8175 - val_loss: 2.6138\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.9711e-04 - val_accuracy: 0.8175 - val_loss: 2.6204\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.9919e-04 - val_accuracy: 0.8175 - val_loss: 2.6266\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.5971e-04 - val_accuracy: 0.8175 - val_loss: 2.6322\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.6632e-04 - val_accuracy: 0.8175 - val_loss: 2.6389\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.6223e-04 - val_accuracy: 0.8175 - val_loss: 2.6453\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.5973e-04 - val_accuracy: 0.8175 - val_loss: 2.6520\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.3056e-04 - val_accuracy: 0.8175 - val_loss: 2.6583\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.1876e-04 - val_accuracy: 0.8175 - val_loss: 2.6650\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0878e-04 - val_accuracy: 0.8175 - val_loss: 2.6721\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.0673e-04 - val_accuracy: 0.8175 - val_loss: 2.6773\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.0367e-04 - val_accuracy: 0.8175 - val_loss: 2.6841\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.4278e-05 - val_accuracy: 0.8175 - val_loss: 2.6909\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 8.9301e-05 - val_accuracy: 0.8175 - val_loss: 2.6985\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 7.7090e-05 - val_accuracy: 0.8175 - val_loss: 2.7052\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 2: loss of 2.148090362548828; compile_metrics of 72.63157963752747%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.5777 - loss: 6.8387 - val_accuracy: 0.7719 - val_loss: 2.1868\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9140 - loss: 0.9116 - val_accuracy: 0.7895 - val_loss: 1.5967\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9801 - loss: 0.2708 - val_accuracy: 0.7789 - val_loss: 1.6988\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9935 - loss: 0.1304 - val_accuracy: 0.8105 - val_loss: 1.7575\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9947 - loss: 0.1016 - val_accuracy: 0.8000 - val_loss: 1.5882\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9951 - loss: 0.1135 - val_accuracy: 0.7860 - val_loss: 1.9691\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9958 - loss: 0.0866 - val_accuracy: 0.7825 - val_loss: 1.6680\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9949 - loss: 0.1143 - val_accuracy: 0.7825 - val_loss: 1.5468\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9953 - loss: 0.0487 - val_accuracy: 0.7965 - val_loss: 1.9012\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0226 - val_accuracy: 0.8105 - val_loss: 2.1357\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0134 - val_accuracy: 0.8105 - val_loss: 2.1513\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0126 - val_accuracy: 0.8140 - val_loss: 1.9959\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.8105 - val_loss: 2.0013\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.8035 - val_loss: 2.0187\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.7965 - val_loss: 2.0369\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7965 - val_loss: 2.0548\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7965 - val_loss: 2.0735\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7965 - val_loss: 2.0900\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.7965 - val_loss: 2.1080\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.7965 - val_loss: 2.1240\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7965 - val_loss: 2.1403\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7965 - val_loss: 2.1560\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7965 - val_loss: 2.1710\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7965 - val_loss: 2.1849\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8000 - val_loss: 2.1994\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8000 - val_loss: 2.2126\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8000 - val_loss: 2.2256\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8000 - val_loss: 2.2387\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 9.5967e-04 - val_accuracy: 0.8000 - val_loss: 2.2507\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7965 - val_loss: 2.2631\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 9.4270e-04 - val_accuracy: 0.7965 - val_loss: 2.2745\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 8.4024e-04 - val_accuracy: 0.7965 - val_loss: 2.2866\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 7.7024e-04 - val_accuracy: 0.7965 - val_loss: 2.2981\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.5063e-04 - val_accuracy: 0.7965 - val_loss: 2.3086\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.6107e-04 - val_accuracy: 0.7965 - val_loss: 2.3193\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.4667e-04 - val_accuracy: 0.8000 - val_loss: 2.3281\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.7107e-04 - val_accuracy: 0.8000 - val_loss: 2.3381\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.3814e-04 - val_accuracy: 0.8000 - val_loss: 2.3479\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.6939e-04 - val_accuracy: 0.8000 - val_loss: 2.3575\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.5348e-04 - val_accuracy: 0.8000 - val_loss: 2.3663\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.0738e-04 - val_accuracy: 0.8000 - val_loss: 2.3749\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.1638e-04 - val_accuracy: 0.8000 - val_loss: 2.3826\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.2867e-04 - val_accuracy: 0.7965 - val_loss: 2.3915\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.9988e-04 - val_accuracy: 0.7965 - val_loss: 2.3989\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.8635e-04 - val_accuracy: 0.7965 - val_loss: 2.4074\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.7972e-04 - val_accuracy: 0.7965 - val_loss: 2.4145\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.6827e-04 - val_accuracy: 0.7965 - val_loss: 2.4219\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.6413e-04 - val_accuracy: 0.7965 - val_loss: 2.4289\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.2725e-04 - val_accuracy: 0.7965 - val_loss: 2.4367\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.0890e-04 - val_accuracy: 0.7965 - val_loss: 2.4437\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 3: loss of 2.1868090629577637; compile_metrics of 77.19298005104065%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.5920 - loss: 5.8250 - val_accuracy: 0.6831 - val_loss: 2.1103\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9377 - loss: 0.4784 - val_accuracy: 0.6761 - val_loss: 2.3379\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9794 - loss: 0.2197 - val_accuracy: 0.6972 - val_loss: 2.0316\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9872 - loss: 0.2863 - val_accuracy: 0.7007 - val_loss: 2.2872\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9916 - loss: 0.1039 - val_accuracy: 0.7113 - val_loss: 2.8642\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9910 - loss: 0.1238 - val_accuracy: 0.7077 - val_loss: 2.4997\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9870 - loss: 0.1628 - val_accuracy: 0.7148 - val_loss: 2.7154\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9802 - loss: 0.2426 - val_accuracy: 0.6937 - val_loss: 2.4894\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9847 - loss: 0.2020 - val_accuracy: 0.7148 - val_loss: 2.5141\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9861 - loss: 0.1317 - val_accuracy: 0.7042 - val_loss: 2.6819\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9867 - loss: 0.2664 - val_accuracy: 0.6937 - val_loss: 2.3933\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9822 - loss: 0.1335 - val_accuracy: 0.7183 - val_loss: 2.5462\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9942 - loss: 0.0818 - val_accuracy: 0.7218 - val_loss: 2.7834\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9950 - loss: 0.0782 - val_accuracy: 0.7289 - val_loss: 2.6790\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9865 - loss: 0.1209 - val_accuracy: 0.6901 - val_loss: 2.7073\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9867 - loss: 0.1136 - val_accuracy: 0.7148 - val_loss: 2.8717\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9893 - loss: 0.1105 - val_accuracy: 0.7218 - val_loss: 4.8185\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9781 - loss: 0.3721 - val_accuracy: 0.7113 - val_loss: 3.0498\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9900 - loss: 0.0790 - val_accuracy: 0.7218 - val_loss: 2.8959\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9987 - loss: 0.0106 - val_accuracy: 0.7254 - val_loss: 2.9604\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7183 - val_loss: 2.9567\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7218 - val_loss: 2.9627\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7218 - val_loss: 2.9694\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 8.8675e-04 - val_accuracy: 0.7218 - val_loss: 2.9746\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 7.9731e-04 - val_accuracy: 0.7218 - val_loss: 2.9805\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 6.7385e-04 - val_accuracy: 0.7218 - val_loss: 2.9857\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 5.8575e-04 - val_accuracy: 0.7218 - val_loss: 2.9913\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 5.2319e-04 - val_accuracy: 0.7218 - val_loss: 2.9965\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 4.1917e-04 - val_accuracy: 0.7218 - val_loss: 3.0017\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.3781e-04 - val_accuracy: 0.7218 - val_loss: 3.0066\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.5553e-04 - val_accuracy: 0.7218 - val_loss: 3.0115\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.3813e-04 - val_accuracy: 0.7218 - val_loss: 3.0161\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.0883e-04 - val_accuracy: 0.7218 - val_loss: 3.0213\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 3.0840e-04 - val_accuracy: 0.7254 - val_loss: 3.0257\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.6273e-04 - val_accuracy: 0.7254 - val_loss: 3.0294\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.3967e-04 - val_accuracy: 0.7254 - val_loss: 3.0330\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 2.4347e-04 - val_accuracy: 0.7254 - val_loss: 3.0366\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1519e-04 - val_accuracy: 0.7254 - val_loss: 3.0403\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7948e-04 - val_accuracy: 0.7254 - val_loss: 3.0438\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.7703e-04 - val_accuracy: 0.7254 - val_loss: 3.0473\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.5505e-04 - val_accuracy: 0.7254 - val_loss: 3.0510\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.4767e-04 - val_accuracy: 0.7254 - val_loss: 3.0542\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.4792e-04 - val_accuracy: 0.7254 - val_loss: 3.0573\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.2758e-04 - val_accuracy: 0.7254 - val_loss: 3.0604\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.1443e-04 - val_accuracy: 0.7254 - val_loss: 3.0636\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.1789e-04 - val_accuracy: 0.7254 - val_loss: 3.0668\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.0614e-04 - val_accuracy: 0.7254 - val_loss: 3.0700\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 1.0785e-04 - val_accuracy: 0.7289 - val_loss: 3.0729\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.0082e-04 - val_accuracy: 0.7289 - val_loss: 3.0761\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 9.3071e-05 - val_accuracy: 0.7289 - val_loss: 3.0792\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 4: loss of 2.110344409942627; compile_metrics of 68.30986142158508%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.6054 - loss: 7.2418 - val_accuracy: 0.7183 - val_loss: 1.7092\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9089 - loss: 0.8162 - val_accuracy: 0.7113 - val_loss: 1.3848\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9695 - loss: 0.3061 - val_accuracy: 0.7852 - val_loss: 1.3357\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9948 - loss: 0.1231 - val_accuracy: 0.7570 - val_loss: 1.3268\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9946 - loss: 0.0913 - val_accuracy: 0.7852 - val_loss: 1.3299\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0353 - val_accuracy: 0.7746 - val_loss: 1.4172\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0331 - val_accuracy: 0.7852 - val_loss: 1.4966\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.7782 - val_loss: 1.4703\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.7782 - val_loss: 1.4763\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.7746 - val_loss: 1.4821\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.7676 - val_loss: 1.4906\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.7676 - val_loss: 1.4984\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7676 - val_loss: 1.5068\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.7676 - val_loss: 1.5151\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.7676 - val_loss: 1.5237\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7676 - val_loss: 1.5326\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.7676 - val_loss: 1.5406\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7641 - val_loss: 1.5489\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7676 - val_loss: 1.5570\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7711 - val_loss: 1.5647\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7711 - val_loss: 1.5728\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7711 - val_loss: 1.5809\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7746 - val_loss: 1.5896\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7746 - val_loss: 1.5982\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.5671e-04 - val_accuracy: 0.7711 - val_loss: 1.6061\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.1762e-04 - val_accuracy: 0.7711 - val_loss: 1.6146\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.5232e-04 - val_accuracy: 0.7711 - val_loss: 1.6227\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 7.1435e-04 - val_accuracy: 0.7711 - val_loss: 1.6297\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.3118e-04 - val_accuracy: 0.7711 - val_loss: 1.6371\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.9298e-04 - val_accuracy: 0.7711 - val_loss: 1.6445\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 5.3776e-04 - val_accuracy: 0.7711 - val_loss: 1.6512\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.9200e-04 - val_accuracy: 0.7711 - val_loss: 1.6585\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 4.5543e-04 - val_accuracy: 0.7676 - val_loss: 1.6654\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.4175e-04 - val_accuracy: 0.7676 - val_loss: 1.6725\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.8646e-04 - val_accuracy: 0.7711 - val_loss: 1.6785\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 3.2309e-04 - val_accuracy: 0.7711 - val_loss: 1.6859\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.0574e-04 - val_accuracy: 0.7711 - val_loss: 1.6922\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 2.6374e-04 - val_accuracy: 0.7711 - val_loss: 1.6985\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 2.8608e-04 - val_accuracy: 0.7711 - val_loss: 1.7053\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.3528e-04 - val_accuracy: 0.7746 - val_loss: 1.7105\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.4306e-04 - val_accuracy: 0.7746 - val_loss: 1.7174\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.1847e-04 - val_accuracy: 0.7746 - val_loss: 1.7234\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.9529e-04 - val_accuracy: 0.7746 - val_loss: 1.7292\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.9372e-04 - val_accuracy: 0.7746 - val_loss: 1.7350\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.8332e-04 - val_accuracy: 0.7746 - val_loss: 1.7405\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.7234e-04 - val_accuracy: 0.7746 - val_loss: 1.7457\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.2983e-04 - val_accuracy: 0.7746 - val_loss: 1.7511\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.5153e-04 - val_accuracy: 0.7746 - val_loss: 1.7562\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.3568e-04 - val_accuracy: 0.7711 - val_loss: 1.7617\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.1648e-04 - val_accuracy: 0.7711 - val_loss: 1.7670\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 5: loss of 1.7091821432113647; compile_metrics of 71.83098793029785%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.6563 - loss: 5.6353 - val_accuracy: 0.6831 - val_loss: 1.8489\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9381 - loss: 0.5473 - val_accuracy: 0.7183 - val_loss: 1.7590\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9911 - loss: 0.1622 - val_accuracy: 0.7077 - val_loss: 1.9866\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9969 - loss: 0.0765 - val_accuracy: 0.7077 - val_loss: 1.7773\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9967 - loss: 0.1141 - val_accuracy: 0.7430 - val_loss: 1.9657\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9952 - loss: 0.1051 - val_accuracy: 0.7324 - val_loss: 1.7994\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9963 - loss: 0.0860 - val_accuracy: 0.7394 - val_loss: 2.3147\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9939 - loss: 0.0483 - val_accuracy: 0.7359 - val_loss: 2.1590\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9933 - loss: 0.0575 - val_accuracy: 0.7218 - val_loss: 2.9351\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9887 - loss: 0.0997 - val_accuracy: 0.7077 - val_loss: 2.7548\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9894 - loss: 0.0909 - val_accuracy: 0.7359 - val_loss: 2.7266\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9950 - loss: 0.0649 - val_accuracy: 0.7218 - val_loss: 2.8693\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9901 - loss: 0.0882 - val_accuracy: 0.7324 - val_loss: 3.2693\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9904 - loss: 0.1255 - val_accuracy: 0.7359 - val_loss: 3.1548\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9918 - loss: 0.1474 - val_accuracy: 0.7641 - val_loss: 3.2943\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9963 - loss: 0.0459 - val_accuracy: 0.7711 - val_loss: 2.9814\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9986 - loss: 0.0131 - val_accuracy: 0.7465 - val_loss: 3.1216\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.7359 - val_loss: 2.9905\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7289 - val_loss: 3.0794\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7218 - val_loss: 3.0596\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7254 - val_loss: 3.0807\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7254 - val_loss: 3.1011\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7254 - val_loss: 3.1219\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 9.5316e-04 - val_accuracy: 0.7289 - val_loss: 3.1424\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 8.7094e-04 - val_accuracy: 0.7289 - val_loss: 3.1637\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 8.1912e-04 - val_accuracy: 0.7289 - val_loss: 3.1843\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.5900e-04 - val_accuracy: 0.7289 - val_loss: 3.2051\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 5.3890e-04 - val_accuracy: 0.7324 - val_loss: 3.2257\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 4.8249e-04 - val_accuracy: 0.7324 - val_loss: 3.2452\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.7091e-04 - val_accuracy: 0.7324 - val_loss: 3.2648\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 4.6391e-04 - val_accuracy: 0.7324 - val_loss: 3.2844\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 3.7346e-04 - val_accuracy: 0.7324 - val_loss: 3.3038\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.7491e-04 - val_accuracy: 0.7324 - val_loss: 3.3211\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 2.8845e-04 - val_accuracy: 0.7324 - val_loss: 3.3396\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.3421e-04 - val_accuracy: 0.7324 - val_loss: 3.3556\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.3415e-04 - val_accuracy: 0.7324 - val_loss: 3.3731\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.1322e-04 - val_accuracy: 0.7324 - val_loss: 3.3889\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 1.9466e-04 - val_accuracy: 0.7324 - val_loss: 3.4038\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.6838e-04 - val_accuracy: 0.7359 - val_loss: 3.4190\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.6795e-04 - val_accuracy: 0.7359 - val_loss: 3.4336\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.2672e-04 - val_accuracy: 0.7359 - val_loss: 3.4478\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.2399e-04 - val_accuracy: 0.7359 - val_loss: 3.4621\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.3088e-04 - val_accuracy: 0.7359 - val_loss: 3.4756\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.2228e-04 - val_accuracy: 0.7359 - val_loss: 3.4879\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.9826e-05 - val_accuracy: 0.7359 - val_loss: 3.5005\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0480e-04 - val_accuracy: 0.7359 - val_loss: 3.5134\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.9664e-05 - val_accuracy: 0.7359 - val_loss: 3.5248\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.3379e-05 - val_accuracy: 0.7359 - val_loss: 3.5356\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 8.7155e-05 - val_accuracy: 0.7359 - val_loss: 3.5489\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 7.6065e-05 - val_accuracy: 0.7359 - val_loss: 3.5608\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 6: loss of 1.848904013633728; compile_metrics of 68.30986142158508%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6130 - loss: 6.8823 - val_accuracy: 0.7042 - val_loss: 2.4552\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9380 - loss: 0.7379 - val_accuracy: 0.7394 - val_loss: 1.7860\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9725 - loss: 0.3114 - val_accuracy: 0.7711 - val_loss: 2.1917\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9934 - loss: 0.2338 - val_accuracy: 0.7394 - val_loss: 2.2688\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0591 - val_accuracy: 0.7641 - val_loss: 2.0923\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9959 - loss: 0.0608 - val_accuracy: 0.7782 - val_loss: 2.1392\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9991 - loss: 0.0512 - val_accuracy: 0.7641 - val_loss: 2.4140\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9970 - loss: 0.0742 - val_accuracy: 0.7042 - val_loss: 2.8064\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9949 - loss: 0.1577 - val_accuracy: 0.7641 - val_loss: 2.1841\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9951 - loss: 0.0684 - val_accuracy: 0.7641 - val_loss: 2.2085\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9799 - loss: 0.3277 - val_accuracy: 0.7465 - val_loss: 2.4625\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9842 - loss: 0.2750 - val_accuracy: 0.7430 - val_loss: 2.9438\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9729 - loss: 0.3685 - val_accuracy: 0.7359 - val_loss: 3.3887\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9771 - loss: 0.2830 - val_accuracy: 0.7676 - val_loss: 2.4433\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9926 - loss: 0.0798 - val_accuracy: 0.7606 - val_loss: 2.6031\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9984 - loss: 0.0143 - val_accuracy: 0.7676 - val_loss: 2.5554\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.7606 - val_loss: 2.5570\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7641 - val_loss: 2.5915\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7606 - val_loss: 2.6069\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7606 - val_loss: 2.6191\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7641 - val_loss: 2.6311\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7641 - val_loss: 2.6434\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7641 - val_loss: 2.6558\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7606 - val_loss: 2.6674\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7606 - val_loss: 2.6794\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.1761e-04 - val_accuracy: 0.7606 - val_loss: 2.6910\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 8.4564e-04 - val_accuracy: 0.7641 - val_loss: 2.7019\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.1275e-04 - val_accuracy: 0.7676 - val_loss: 2.7128\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.9908e-04 - val_accuracy: 0.7676 - val_loss: 2.7226\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.9718e-04 - val_accuracy: 0.7676 - val_loss: 2.7327\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 5.1742e-04 - val_accuracy: 0.7676 - val_loss: 2.7420\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.4285e-04 - val_accuracy: 0.7676 - val_loss: 2.7514\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.4601e-04 - val_accuracy: 0.7676 - val_loss: 2.7614\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.7817e-04 - val_accuracy: 0.7676 - val_loss: 2.7707\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.3238e-04 - val_accuracy: 0.7676 - val_loss: 2.7797\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.6647e-04 - val_accuracy: 0.7676 - val_loss: 2.7881\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.7570e-04 - val_accuracy: 0.7711 - val_loss: 2.7969\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.3399e-04 - val_accuracy: 0.7711 - val_loss: 2.8051\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.2689e-04 - val_accuracy: 0.7711 - val_loss: 2.8132\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 2.1427e-04 - val_accuracy: 0.7711 - val_loss: 2.8215\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.9747e-04 - val_accuracy: 0.7711 - val_loss: 2.8297\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.8624e-04 - val_accuracy: 0.7711 - val_loss: 2.8378\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.7286e-04 - val_accuracy: 0.7711 - val_loss: 2.8454\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.5316e-04 - val_accuracy: 0.7711 - val_loss: 2.8532\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.2995e-04 - val_accuracy: 0.7711 - val_loss: 2.8599\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.3035e-04 - val_accuracy: 0.7676 - val_loss: 2.8673\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.3713e-04 - val_accuracy: 0.7676 - val_loss: 2.8750\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.2605e-04 - val_accuracy: 0.7676 - val_loss: 2.8819\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.0930e-04 - val_accuracy: 0.7676 - val_loss: 2.8885\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.8001e-05 - val_accuracy: 0.7676 - val_loss: 2.8950\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 7: loss of 2.455219030380249; compile_metrics of 70.42253613471985%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5934 - loss: 5.9739 - val_accuracy: 0.7570 - val_loss: 1.4406\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9284 - loss: 0.6667 - val_accuracy: 0.7782 - val_loss: 1.3709\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9904 - loss: 0.1325 - val_accuracy: 0.7923 - val_loss: 1.4151\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9941 - loss: 0.0927 - val_accuracy: 0.7570 - val_loss: 1.5853\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0558 - val_accuracy: 0.7324 - val_loss: 1.7581\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9951 - loss: 0.0733 - val_accuracy: 0.7782 - val_loss: 1.7048\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9987 - loss: 0.0481 - val_accuracy: 0.7887 - val_loss: 1.9377\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9993 - loss: 0.0259 - val_accuracy: 0.8028 - val_loss: 1.8183\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9994 - loss: 0.0362 - val_accuracy: 0.7570 - val_loss: 2.0562\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9938 - loss: 0.0679 - val_accuracy: 0.7817 - val_loss: 1.8518\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9948 - loss: 0.0576 - val_accuracy: 0.7500 - val_loss: 1.8664\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9910 - loss: 0.0676 - val_accuracy: 0.7746 - val_loss: 2.3428\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9932 - loss: 0.0667 - val_accuracy: 0.7923 - val_loss: 2.1156\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9947 - loss: 0.0396 - val_accuracy: 0.7887 - val_loss: 2.7318\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9916 - loss: 0.0963 - val_accuracy: 0.7711 - val_loss: 2.0251\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9970 - loss: 0.0226 - val_accuracy: 0.7852 - val_loss: 2.3112\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9966 - loss: 0.0345 - val_accuracy: 0.8099 - val_loss: 2.1716\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9877 - loss: 0.0834 - val_accuracy: 0.7923 - val_loss: 2.3985\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9874 - loss: 0.0862 - val_accuracy: 0.7782 - val_loss: 2.1423\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9927 - loss: 0.0469 - val_accuracy: 0.7958 - val_loss: 2.8039\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9941 - loss: 0.0215 - val_accuracy: 0.7746 - val_loss: 2.4940\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9940 - loss: 0.0228 - val_accuracy: 0.7676 - val_loss: 2.5678\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9985 - loss: 0.0138 - val_accuracy: 0.7852 - val_loss: 2.6391\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9976 - loss: 0.0346 - val_accuracy: 0.7042 - val_loss: 3.4599\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9866 - loss: 0.1163 - val_accuracy: 0.7500 - val_loss: 3.6786\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9772 - loss: 0.2884 - val_accuracy: 0.7324 - val_loss: 3.0971\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9598 - loss: 0.5640 - val_accuracy: 0.7711 - val_loss: 3.1256\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9879 - loss: 0.1158 - val_accuracy: 0.7746 - val_loss: 2.5449\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9915 - loss: 0.0684 - val_accuracy: 0.7535 - val_loss: 2.4558\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9983 - loss: 0.0196 - val_accuracy: 0.7641 - val_loss: 2.5247\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9971 - loss: 0.0323 - val_accuracy: 0.7606 - val_loss: 2.7898\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9976 - loss: 0.0552 - val_accuracy: 0.7641 - val_loss: 2.7025\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7570 - val_loss: 2.6169\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 4.8364e-04 - val_accuracy: 0.7641 - val_loss: 2.6260\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 3.7430e-04 - val_accuracy: 0.7641 - val_loss: 2.6319\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 3.9986e-04 - val_accuracy: 0.7641 - val_loss: 2.6374\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 3.0279e-04 - val_accuracy: 0.7641 - val_loss: 2.6424\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.1805e-04 - val_accuracy: 0.7641 - val_loss: 2.6477\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 2.7825e-04 - val_accuracy: 0.7641 - val_loss: 2.6528\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.4953e-04 - val_accuracy: 0.7606 - val_loss: 2.6579\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 2.3471e-04 - val_accuracy: 0.7606 - val_loss: 2.6623\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.9851e-04 - val_accuracy: 0.7606 - val_loss: 2.6671\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 2.0486e-04 - val_accuracy: 0.7606 - val_loss: 2.6717\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.8686e-04 - val_accuracy: 0.7606 - val_loss: 2.6760\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 1.6313e-04 - val_accuracy: 0.7606 - val_loss: 2.6802\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.5709e-04 - val_accuracy: 0.7641 - val_loss: 2.6843\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.5657e-04 - val_accuracy: 0.7641 - val_loss: 2.6883\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 1.6031e-04 - val_accuracy: 0.7641 - val_loss: 2.6923\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.4246e-04 - val_accuracy: 0.7641 - val_loss: 2.6962\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.2242e-04 - val_accuracy: 0.7641 - val_loss: 2.6998\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 8: loss of 1.4405730962753296; compile_metrics of 75.70422291755676%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.6101 - loss: 5.0124 - val_accuracy: 0.7007 - val_loss: 1.6357\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9111 - loss: 0.5858 - val_accuracy: 0.6725 - val_loss: 1.3384\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9562 - loss: 0.3112 - val_accuracy: 0.7465 - val_loss: 1.3298\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9861 - loss: 0.1544 - val_accuracy: 0.7676 - val_loss: 1.4104\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9954 - loss: 0.0964 - val_accuracy: 0.7359 - val_loss: 1.5322\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9863 - loss: 0.1423 - val_accuracy: 0.7641 - val_loss: 1.4019\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9909 - loss: 0.1137 - val_accuracy: 0.7535 - val_loss: 1.5177\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9879 - loss: 0.1222 - val_accuracy: 0.7394 - val_loss: 1.4839\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9904 - loss: 0.0594 - val_accuracy: 0.7852 - val_loss: 1.7289\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9964 - loss: 0.0316 - val_accuracy: 0.7887 - val_loss: 1.5460\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0136 - val_accuracy: 0.7746 - val_loss: 1.6505\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.7641 - val_loss: 1.7000\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7641 - val_loss: 1.7435\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7641 - val_loss: 1.7815\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.7641 - val_loss: 1.8131\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7641 - val_loss: 1.8378\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7641 - val_loss: 1.8602\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7641 - val_loss: 1.8805\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7641 - val_loss: 1.9024\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7641 - val_loss: 1.9231\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7641 - val_loss: 1.9386\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 9.0908e-04 - val_accuracy: 0.7641 - val_loss: 1.9559\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 8.1639e-04 - val_accuracy: 0.7641 - val_loss: 1.9743\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.9624e-04 - val_accuracy: 0.7641 - val_loss: 1.9870\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 5.7162e-04 - val_accuracy: 0.7641 - val_loss: 1.9986\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.9139e-04 - val_accuracy: 0.7606 - val_loss: 2.0130\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 4.3241e-04 - val_accuracy: 0.7606 - val_loss: 2.0299\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.9415e-04 - val_accuracy: 0.7570 - val_loss: 2.0420\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 3.8903e-04 - val_accuracy: 0.7535 - val_loss: 2.0541\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 3.1763e-04 - val_accuracy: 0.7535 - val_loss: 2.0606\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.8778e-04 - val_accuracy: 0.7570 - val_loss: 2.0711\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.6538e-04 - val_accuracy: 0.7570 - val_loss: 2.0819\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.4296e-04 - val_accuracy: 0.7570 - val_loss: 2.0957\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.4018e-04 - val_accuracy: 0.7606 - val_loss: 2.1044\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.2694e-04 - val_accuracy: 0.7606 - val_loss: 2.1107\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.8947e-04 - val_accuracy: 0.7606 - val_loss: 2.1238\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.8664e-04 - val_accuracy: 0.7641 - val_loss: 2.1324\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.8404e-04 - val_accuracy: 0.7641 - val_loss: 2.1435\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.6366e-04 - val_accuracy: 0.7606 - val_loss: 2.1527\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 1.4335e-04 - val_accuracy: 0.7606 - val_loss: 2.1654\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.4138e-04 - val_accuracy: 0.7606 - val_loss: 2.1694\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.2581e-04 - val_accuracy: 0.7606 - val_loss: 2.1808\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.1760e-04 - val_accuracy: 0.7606 - val_loss: 2.1921\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0880e-04 - val_accuracy: 0.7606 - val_loss: 2.2018\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 1.0988e-04 - val_accuracy: 0.7606 - val_loss: 2.2124\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.1927e-04 - val_accuracy: 0.7606 - val_loss: 2.2208\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 9.9684e-05 - val_accuracy: 0.7641 - val_loss: 2.2295\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.3684e-05 - val_accuracy: 0.7641 - val_loss: 2.2359\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0201e-04 - val_accuracy: 0.7641 - val_loss: 2.2425\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.7056e-05 - val_accuracy: 0.7606 - val_loss: 2.2492\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 9: loss of 1.635685682296753; compile_metrics of 70.07042169570923%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/opt/anaconda3/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.6023 - loss: 7.1723 - val_accuracy: 0.6937 - val_loss: 2.0619\n",
      "Epoch 2/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8918 - loss: 1.0285 - val_accuracy: 0.7183 - val_loss: 1.7156\n",
      "Epoch 3/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9844 - loss: 0.1467 - val_accuracy: 0.7641 - val_loss: 1.7606\n",
      "Epoch 4/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9950 - loss: 0.0724 - val_accuracy: 0.7570 - val_loss: 1.7026\n",
      "Epoch 5/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9992 - loss: 0.0429 - val_accuracy: 0.7500 - val_loss: 1.6895\n",
      "Epoch 6/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9969 - loss: 0.0507 - val_accuracy: 0.7641 - val_loss: 1.9438\n",
      "Epoch 7/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9960 - loss: 0.0435 - val_accuracy: 0.7570 - val_loss: 1.9741\n",
      "Epoch 8/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9888 - loss: 0.2367 - val_accuracy: 0.7113 - val_loss: 2.3556\n",
      "Epoch 9/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9827 - loss: 0.1554 - val_accuracy: 0.7570 - val_loss: 1.9741\n",
      "Epoch 10/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9985 - loss: 0.0478 - val_accuracy: 0.7923 - val_loss: 2.1180\n",
      "Epoch 11/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9943 - loss: 0.0533 - val_accuracy: 0.7711 - val_loss: 2.0779\n",
      "Epoch 12/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9958 - loss: 0.0294 - val_accuracy: 0.7887 - val_loss: 2.2701\n",
      "Epoch 13/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9931 - loss: 0.1216 - val_accuracy: 0.7465 - val_loss: 2.6811\n",
      "Epoch 14/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9812 - loss: 0.1998 - val_accuracy: 0.7782 - val_loss: 1.8920\n",
      "Epoch 15/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9900 - loss: 0.1007 - val_accuracy: 0.7500 - val_loss: 2.1273\n",
      "Epoch 16/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9923 - loss: 0.0711 - val_accuracy: 0.7641 - val_loss: 1.5569\n",
      "Epoch 17/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9962 - loss: 0.0182 - val_accuracy: 0.7711 - val_loss: 1.6551\n",
      "Epoch 18/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9975 - loss: 0.0735 - val_accuracy: 0.7711 - val_loss: 1.8172\n",
      "Epoch 19/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9968 - loss: 0.0446 - val_accuracy: 0.7958 - val_loss: 1.6770\n",
      "Epoch 20/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9961 - loss: 0.0237 - val_accuracy: 0.7923 - val_loss: 1.9105\n",
      "Epoch 21/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9989 - loss: 0.0058 - val_accuracy: 0.7817 - val_loss: 2.0402\n",
      "Epoch 22/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9990 - loss: 0.0166 - val_accuracy: 0.8028 - val_loss: 1.9910\n",
      "Epoch 23/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9865 - loss: 0.2587 - val_accuracy: 0.7711 - val_loss: 2.3423\n",
      "Epoch 24/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9950 - loss: 0.0329 - val_accuracy: 0.7676 - val_loss: 2.2275\n",
      "Epoch 25/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9933 - loss: 0.0460 - val_accuracy: 0.7746 - val_loss: 2.0872\n",
      "Epoch 26/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9853 - loss: 0.1673 - val_accuracy: 0.7430 - val_loss: 2.7732\n",
      "Epoch 27/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9890 - loss: 0.0747 - val_accuracy: 0.7711 - val_loss: 2.4659\n",
      "Epoch 28/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9925 - loss: 0.0511 - val_accuracy: 0.7817 - val_loss: 2.5966\n",
      "Epoch 29/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9959 - loss: 0.0305 - val_accuracy: 0.7993 - val_loss: 2.5964\n",
      "Epoch 30/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9883 - loss: 0.0918 - val_accuracy: 0.7465 - val_loss: 2.3907\n",
      "Epoch 31/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9781 - loss: 0.5131 - val_accuracy: 0.7289 - val_loss: 3.7856\n",
      "Epoch 32/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9561 - loss: 0.6028 - val_accuracy: 0.7535 - val_loss: 2.7184\n",
      "Epoch 33/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9791 - loss: 0.2580 - val_accuracy: 0.7676 - val_loss: 2.4836\n",
      "Epoch 34/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9783 - loss: 0.1837 - val_accuracy: 0.7535 - val_loss: 2.2326\n",
      "Epoch 35/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0870 - val_accuracy: 0.7782 - val_loss: 2.5586\n",
      "Epoch 36/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9957 - loss: 0.0364 - val_accuracy: 0.7641 - val_loss: 2.3734\n",
      "Epoch 37/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0068 - val_accuracy: 0.7676 - val_loss: 2.8798\n",
      "Epoch 38/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.7676 - val_loss: 2.4950\n",
      "Epoch 39/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 6.3085e-04 - val_accuracy: 0.7746 - val_loss: 2.4956\n",
      "Epoch 40/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.6584e-04 - val_accuracy: 0.7746 - val_loss: 2.5063\n",
      "Epoch 41/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.0540e-04 - val_accuracy: 0.7746 - val_loss: 2.5162\n",
      "Epoch 42/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.5214e-04 - val_accuracy: 0.7746 - val_loss: 2.5267\n",
      "Epoch 43/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.6844e-04 - val_accuracy: 0.7746 - val_loss: 2.5367\n",
      "Epoch 44/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.9341e-04 - val_accuracy: 0.7746 - val_loss: 2.5456\n",
      "Epoch 45/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 2.5886e-04 - val_accuracy: 0.7746 - val_loss: 2.5547\n",
      "Epoch 46/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.4787e-04 - val_accuracy: 0.7782 - val_loss: 2.5641\n",
      "Epoch 47/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 2.4072e-04 - val_accuracy: 0.7817 - val_loss: 2.5724\n",
      "Epoch 48/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.3897e-04 - val_accuracy: 0.7817 - val_loss: 2.5810\n",
      "Epoch 49/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 2.1121e-04 - val_accuracy: 0.7817 - val_loss: 2.5886\n",
      "Epoch 50/150\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.7454e-04 - val_accuracy: 0.7817 - val_loss: 2.5964\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Score for fold 10: loss of 2.0618906021118164; compile_metrics of 69.36619877815247%\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cross validation with keras and scikit-learn f1 score on validation set\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "f1 = []\n",
    "print(X_train_ROS_combined.shape)\n",
    "print(y_train_ROS_combined.shape)\n",
    "for train, test in kfold.split(X_train_ROS_combined, y_train_ROS_combined):\n",
    "  # Validation set\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(256, input_shape=(48*48,), activation='relu')) \n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dense((64), activation='relu'))\n",
    "  model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "  adam = keras.optimizers.Adam(learning_rate = lr)\n",
    "  model.compile(optimizer = adam,\n",
    "                loss = ['binary_crossentropy'],\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  # Fit data to model\n",
    "  history = model.fit(X_train_ROS_combined[train], train_labels_ROS_combined[train],\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs,\n",
    "                      verbose=1,\n",
    "                      validation_data=(X_train_ROS_combined[test], train_labels_ROS_combined[test]),\n",
    "                      callbacks = [early_stopping]\n",
    "                      )\n",
    "\n",
    "  # Generate generalization metrics on validation set\n",
    "  scores = model.evaluate(X_train_ROS_combined[test], train_labels_ROS_combined[test], verbose=0)\n",
    "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "  f1.append(f1_score(np.argmax(train_labels_ROS_combined[test],axis=1),np.argmax(model.predict(X_train_ROS_combined[test]),axis=1)))\n",
    "  fold_no += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7361963190184051, 0.6904761904761905, 0.7811447811447811, 0.7019867549668874, 0.7499999999999999, 0.7019867549668873, 0.6956521739130436, 0.7752442996742671, 0.711864406779661, 0.6614785992217899]\n"
     ]
    }
   ],
   "source": [
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
